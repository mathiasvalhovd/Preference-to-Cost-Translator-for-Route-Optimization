{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection Pipeline for Preference-to-Cost ML Model\n",
        "\n",
        "This notebook collects 200 training samples by:\n",
        "1. Sampling random preferences\n",
        "2. Translating to cost parameters\n",
        "3. Sending to ODL API\n",
        "4. Collecting route results\n",
        "\n",
        "**Estimated time**: ~5 hours (200 samples Ã— 90 seconds each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Imports successful\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import copy\n",
        "\n",
        "print(\"âœ“ Imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# One folder out\n",
        "with open('../../test_model_mathias_fixed.json', 'r') as f:\n",
        "    model = json.load(f)\n",
        "\n",
        "# Remove complete jobs (this removes both pickup + delivery)\n",
        "model['data']['jobs'] = model['data']['jobs'][:25]  # Keep first 25 jobs\n",
        "\n",
        "# Remove vehicles\n",
        "model['data']['vehicles'] = model['data']['vehicles'][:8]  # Keep 8 vehicles\n",
        "\n",
        "# Save\n",
        "with open('test_model_25jobs_8vehicles.json', 'w') as f:\n",
        "    json.dump(model, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "**âš ï¸ CHANGE THESE VALUES:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Base URL: https://optimizer-0.staging.zenderatms.com\n",
            "  Model: test_model_25jobs_8vehicles.json\n",
            "  Samples to collect: 200\n",
            "  Output: training_data.json\n"
          ]
        }
      ],
      "source": [
        "# API Configuration\n",
        " \n",
        "\n",
        "# Model file (25 jobs, 8 vehicles)\n",
        "MODEL_PATH = \"test_model_25jobs_8vehicles.json\"  \n",
        "\n",
        "# Data collection settings\n",
        "N_SAMPLES = 200\n",
        "OUTPUT_FILE = \"training_data.json\"\n",
        "CHECKPOINT_EVERY = 10  # Save every 10 samples\n",
        "WAIT_SECONDS = 90  # Wait time for optimization\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Base URL: {BASE_URL}\")\n",
        "print(f\"  Model: {MODEL_PATH}\")\n",
        "print(f\"  Samples to collect: {N_SAMPLES}\")\n",
        "print(f\"  Output: {OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collector Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PreferenceCostDataCollector:\n",
        "    \"\"\"Collects training data for preference-to-cost translation\"\"\"\n",
        "    \n",
        "    def __init__(self, base_url, username, password, model_path):\n",
        "        \"\"\"Initialize data collector\"\"\"\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        \n",
        "        # Initialize session\n",
        "        self.session = requests.Session()\n",
        "        self.session.auth = (username, password)\n",
        "        self.session.headers.update({\n",
        "            'Content-Type': 'application/json',\n",
        "            'Accept': 'application/json'\n",
        "        })\n",
        "        \n",
        "        # Load base model\n",
        "        with open(model_path, 'r') as f:\n",
        "            self.base_model = json.load(f)\n",
        "        \n",
        "        print(f\"âœ“ Base model loaded\")\n",
        "        print(f\"  Jobs: {len(self.base_model['data']['jobs'])}\")\n",
        "        print(f\"  Vehicles: {len(self.base_model['data']['vehicles'])}\")\n",
        "        \n",
        "        # Data storage\n",
        "        self.collected_data = []\n",
        "    \n",
        "    def sample_preferences(self):\n",
        "        \"\"\"Sample random preference values\"\"\"\n",
        "        preferences = {\n",
        "            'parking_importance': np.random.uniform(0.0, 1.0),\n",
        "            'time_importance': np.random.uniform(0.0, 1.0),\n",
        "            'distance_importance': np.random.uniform(0.0, 1.0)\n",
        "        }\n",
        "        return preferences\n",
        "    \n",
        "    def preferences_to_costs(self, preferences):\n",
        "        \"\"\"Translate preferences to cost parameters using heuristic\"\"\"\n",
        "        # Baseline costs\n",
        "        baseline_cost_per_hour = 1.0\n",
        "        baseline_cost_per_km = 0.028\n",
        "        baseline_parking_mult = 1.0\n",
        "        \n",
        "        # Map preferences to costs\n",
        "        # High time_importance -> increase costPerTravelHour (range: 0.5 to 5.0)\n",
        "        cost_per_travel_hour = baseline_cost_per_hour * (0.5 + preferences['time_importance'] * 4.5)\n",
        "        \n",
        "        # High distance_importance -> increase costPerKm (range: 0.014 to 0.49)\n",
        "        cost_per_km = baseline_cost_per_km * (0.5 + preferences['distance_importance'] * 17.0)\n",
        "        \n",
        "        # High parking_importance -> increase parking multiplier (range: 0.2 to 5.0)\n",
        "        parking_multiplier = baseline_parking_mult * (0.2 + preferences['parking_importance'] * 4.8)\n",
        "        \n",
        "        costs = {\n",
        "            'costPerTravelHour': round(cost_per_travel_hour, 3),\n",
        "            'costPerKm': round(cost_per_km, 4),\n",
        "            'parking_multiplier': round(parking_multiplier, 2)\n",
        "        }\n",
        "        \n",
        "        return costs\n",
        "    \n",
        "    # watch out for parking cost on pickup stops\n",
        "    def apply_costs_to_model(self, costs):\n",
        "        \"\"\"Apply cost parameters to model\"\"\"\n",
        "        model = copy.deepcopy(self.base_model)\n",
        "        \n",
        "        # Apply vehicle costs\n",
        "        for vehicle in model['data']['vehicles']:\n",
        "            if 'definition' in vehicle:\n",
        "                vehicle['definition']['costPerTravelHour'] = costs['costPerTravelHour']\n",
        "                vehicle['definition']['costPerKm'] = costs['costPerKm']\n",
        "        \n",
        "        # Apply parking multiplier\n",
        "        for job in model['data']['jobs']:\n",
        "            for stop in job.get('stops', []):\n",
        "                if 'parking' in stop and 'cost' in stop['parking']:\n",
        "                    original_cost = stop['parking']['cost']\n",
        "                    stop['parking']['cost'] = original_cost * costs['parking_multiplier']\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def send_to_odl(self, model, model_id):\n",
        "        \"\"\"Send model to ODL API\"\"\"\n",
        "        url = f\"{self.base_url}/models/{model_id}\"\n",
        "        \n",
        "        try:\n",
        "            response = self.session.put(url, json=model, timeout=60)\n",
        "            \n",
        "            if response.status_code in [200, 201, 204]:\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"  âœ— PUT failed: {response.status_code}\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Error: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_plan(self, model_id, wait_seconds=90):\n",
        "        \"\"\"Get optimized plan from ODL\"\"\"\n",
        "        # Wait for optimization\n",
        "        time.sleep(wait_seconds)\n",
        "        \n",
        "        url = f\"{self.base_url}/models/{model_id}/optimiserstate/plan\"\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, timeout=30)\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            else:\n",
        "                print(f\"  âœ— GET failed: {response.status_code}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def delete_model(self, model_id):\n",
        "        \"\"\"Delete model from server\"\"\"\n",
        "        url = f\"{self.base_url}/models/{model_id}\"\n",
        "        try:\n",
        "            self.session.delete(url, timeout=10)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    def extract_route_features(self, plan):\n",
        "        \"\"\"Extract features from optimized routes\"\"\"\n",
        "        vehicle_plans = plan.get('vehiclePlans', [])\n",
        "        \n",
        "        # Aggregate metrics\n",
        "        total_distance_m = 0\n",
        "        total_travel_seconds = 0\n",
        "        total_cost = 0\n",
        "        total_stops = 0\n",
        "        \n",
        "        for vehicle in vehicle_plans:\n",
        "            time_stats = vehicle.get('timeStatistics', {})\n",
        "            total_distance_m += time_stats.get('travelMetres', 0)\n",
        "            total_travel_seconds += time_stats.get('travelSeconds', 0)\n",
        "            total_cost += time_stats.get('cost', 0)\n",
        "            \n",
        "            stops = vehicle.get('plannedStops', [])\n",
        "            total_stops += len(stops)\n",
        "        \n",
        "        features = {\n",
        "            'total_distance_km': total_distance_m / 1000,\n",
        "            'total_travel_hours': total_travel_seconds / 3600,\n",
        "            'total_cost': total_cost,\n",
        "            'total_stops': total_stops,\n",
        "            'vehicles_used': sum(1 for v in vehicle_plans if len(v.get('plannedStops', [])) > 0),\n",
        "            'unplanned_jobs': len(plan.get('unplannedJobs', []))\n",
        "        }\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    def collect_sample(self, sample_num, wait_seconds=90):\n",
        "        \"\"\"Collect one training sample\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Sample {sample_num}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # 1. Sample preferences\n",
        "        preferences = self.sample_preferences()\n",
        "        print(f\"Preferences:\")\n",
        "        print(f\"  parking_importance: {preferences['parking_importance']:.3f}\")\n",
        "        print(f\"  time_importance: {preferences['time_importance']:.3f}\")\n",
        "        print(f\"  distance_importance: {preferences['distance_importance']:.3f}\")\n",
        "        \n",
        "        # 2. Translate to costs\n",
        "        costs = self.preferences_to_costs(preferences)\n",
        "        print(f\"Costs:\")\n",
        "        print(f\"  costPerTravelHour: {costs['costPerTravelHour']:.3f}\")\n",
        "        print(f\"  costPerKm: {costs['costPerKm']:.4f}\")\n",
        "        print(f\"  parking_multiplier: {costs['parking_multiplier']:.2f}\")\n",
        "        \n",
        "        # 3. Apply costs to model\n",
        "        model = self.apply_costs_to_model(costs)\n",
        "        \n",
        "        # 4. Send to ODL\n",
        "        model_id = f\"sample_{sample_num}_{int(time.time())}\"\n",
        "        print(f\"Sending to ODL (ID: {model_id})...\")\n",
        "        \n",
        "        if not self.send_to_odl(model, model_id):\n",
        "            print(f\"  âœ— Failed to send model\")\n",
        "            return None\n",
        "        \n",
        "        print(f\"  âœ“ Model uploaded, waiting {wait_seconds} seconds for optimization...\")\n",
        "        \n",
        "        # 5. Get plan\n",
        "        plan = self.get_plan(model_id, wait_seconds=wait_seconds)\n",
        "        \n",
        "        if plan is None:\n",
        "            print(f\"  âœ— Failed to get plan\")\n",
        "            self.delete_model(model_id)\n",
        "            return None\n",
        "        \n",
        "        # 6. Extract features\n",
        "        features = self.extract_route_features(plan)\n",
        "        print(f\"Route features:\")\n",
        "        print(f\"  distance: {features['total_distance_km']:.2f} km\")\n",
        "        print(f\"  time: {features['total_travel_hours']:.2f} hours\")\n",
        "        print(f\"  cost: {features['total_cost']:.2f}\")\n",
        "        print(f\"  stops: {features['total_stops']}\")\n",
        "        print(f\"  vehicles: {features['vehicles_used']}\")\n",
        "        \n",
        "        # 7. Clean up\n",
        "        self.delete_model(model_id)\n",
        "        \n",
        "        # 8. Create sample\n",
        "        sample = {\n",
        "            'sample_num': sample_num,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'preferences': preferences,\n",
        "            'costs': costs,\n",
        "            'features': features\n",
        "        }\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def save_data(self, output_file):\n",
        "        \"\"\"Save collected data to JSON file\"\"\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(self.collected_data, f, indent=2)\n",
        "        print(f\"ðŸ’¾ Saved {len(self.collected_data)} samples to {output_file}\")\n",
        "\n",
        "print(\"âœ“ Class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Data Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate configuration\n",
        "if USERNAME == \"your-username\" or PASSWORD == \"your-password\":\n",
        "    print(\"âŒ ERROR: Please set your USERNAME and PASSWORD in the configuration cell above!\")\n",
        "else:\n",
        "    # Initialize collector\n",
        "    collector = PreferenceCostDataCollector(\n",
        "        base_url=BASE_URL,\n",
        "        username=USERNAME,\n",
        "        password=PASSWORD,\n",
        "        model_path=MODEL_PATH\n",
        "    )\n",
        "    print(\"\\nâœ“ Collector initialized and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test with Single Sample\n",
        "\n",
        "Run this first to make sure everything works before collecting all 200 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with one sample\n",
        "test_sample = collector.collect_sample(sample_num=0, wait_seconds=WAIT_SECONDS)\n",
        "\n",
        "if test_sample:\n",
        "    print(\"\\nâœ“ Test successful!\")\n",
        "    print(\"\\nSample data structure:\")\n",
        "    print(json.dumps(test_sample, indent=2))\n",
        "else:\n",
        "    print(\"\\nâœ— Test failed - check your configuration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collect Full Dataset\n",
        "\n",
        "âš ï¸ **This will take ~5 hours to complete!**\n",
        "\n",
        "The notebook will:\n",
        "- Collect 200 samples\n",
        "- Save checkpoints every 10 samples\n",
        "- Show progress and time estimates\n",
        "\n",
        "You can interrupt with Kernel â†’ Interrupt and your data will be saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DATA COLLECTION PIPELINE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Target samples: {N_SAMPLES}\")\n",
        "print(f\"Output file: {OUTPUT_FILE}\")\n",
        "print(f\"Checkpoint every: {CHECKPOINT_EVERY} samples\")\n",
        "print(f\"Wait time: {WAIT_SECONDS} seconds per sample\")\n",
        "print(f\"Estimated total time: {(N_SAMPLES * WAIT_SECONDS) / 3600:.1f} hours\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    for i in range(1, N_SAMPLES + 1):\n",
        "        try:\n",
        "            sample = collector.collect_sample(i, wait_seconds=WAIT_SECONDS)\n",
        "            \n",
        "            if sample is not None:\n",
        "                collector.collected_data.append(sample)\n",
        "                print(f\"âœ“ Sample {i} collected successfully\")\n",
        "            else:\n",
        "                print(f\"âœ— Sample {i} failed, skipping...\")\n",
        "            \n",
        "            # Save checkpoint\n",
        "            if i % CHECKPOINT_EVERY == 0:\n",
        "                collector.save_data(OUTPUT_FILE)\n",
        "                elapsed = time.time() - start_time\n",
        "                avg_time = elapsed / i\n",
        "                remaining = (N_SAMPLES - i) * avg_time\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"CHECKPOINT: {i}/{N_SAMPLES} samples collected\")\n",
        "                print(f\"Elapsed: {elapsed/60:.1f} minutes\")\n",
        "                print(f\"Estimated remaining: {remaining/60:.1f} minutes\")\n",
        "                print(f\"{'='*60}\\n\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"âœ— Unexpected error on sample {i}: {e}\")\n",
        "            continue\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(f\"\\n\\nInterrupted by user!\")\n",
        "    print(f\"Collected {len(collector.collected_data)} samples so far\")\n",
        "\n",
        "# Final save\n",
        "collector.save_data(OUTPUT_FILE)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DATA COLLECTION COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total samples collected: {len(collector.collected_data)}\")\n",
        "print(f\"Total time: {elapsed/60:.1f} minutes\")\n",
        "if len(collector.collected_data) > 0:\n",
        "    print(f\"Average time per sample: {elapsed/len(collector.collected_data):.1f} seconds\")\n",
        "print(f\"Data saved to: {OUTPUT_FILE}\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Collected Data\n",
        "\n",
        "Quick analysis of the collected dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the collected data\n",
        "with open(OUTPUT_FILE, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"Dataset Summary:\")\n",
        "print(f\"  Total samples: {len(data)}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "df_records = []\n",
        "for sample in data:\n",
        "    record = {\n",
        "        'sample_num': sample['sample_num'],\n",
        "        **{f'pref_{k}': v for k, v in sample['preferences'].items()},\n",
        "        **{f'cost_{k}': v for k, v in sample['costs'].items()},\n",
        "        **{f'feat_{k}': v for k, v in sample['features'].items()}\n",
        "    }\n",
        "    df_records.append(record)\n",
        "\n",
        "df = pd.DataFrame(df_records)\n",
        "\n",
        "print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\nPreferences statistics:\")\n",
        "print(df[['pref_parking_importance', 'pref_time_importance', 'pref_distance_importance']].describe())\n",
        "\n",
        "print(f\"\\nCosts statistics:\")\n",
        "print(df[['cost_costPerTravelHour', 'cost_costPerKm', 'cost_parking_multiplier']].describe())\n",
        "\n",
        "print(f\"\\nFeatures statistics:\")\n",
        "print(df[['feat_total_distance_km', 'feat_total_travel_hours', 'feat_total_cost']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have collected the training data:\n",
        "\n",
        "1. âœ… **Data collected**: `training_data.json`\n",
        "2. ðŸ”œ **Train regression model**: preferences â†’ costs\n",
        "3. ðŸ”œ **Validate model performance**\n",
        "4. ðŸ”œ **Deploy for real-time preference translation**\n",
        "\n",
        "The next notebook will focus on training the ML model!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
