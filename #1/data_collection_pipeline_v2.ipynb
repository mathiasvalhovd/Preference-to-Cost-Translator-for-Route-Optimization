{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection Pipeline V2 - Pareto-Based Evaluation\n",
        "\n",
        "This notebook collects 200 training samples using a **better approach**:\n",
        "\n",
        "## Old Approach (V1):\n",
        "1. Sample random preferences\n",
        "2. Use fixed heuristic to translate preferences â†’ costs\n",
        "3. Optimize with those costs\n",
        "4. Save (preferences, costs, features)\n",
        "\n",
        "**Problem**: Model just learns our fixed heuristic!\n",
        "\n",
        "## New Approach (V2):\n",
        "1. Sample random preferences\n",
        "2. Generate 5 random cost sets **independently**\n",
        "3. Optimize each cost set (5 solutions)\n",
        "4. Score each solution against preferences\n",
        "5. Pick the cost set that produces the best-matching solution\n",
        "6. Save (preferences, best_costs, best_features)\n",
        "\n",
        "**Benefit**: Model learns the actual relationship between preferences and optimal costs!\n",
        "\n",
        "**Estimated time**: ~15-20 hours (200 samples Ã— 5 optimizations Ã— 90 seconds each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import copy\n",
        "\n",
        "print(\"âœ“ Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "**âš ï¸ CHANGE THESE VALUES:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API Configuration\n",
        "\n",
        "\n",
        "# Model file (25 jobs, 8 vehicles)\n",
        "MODEL_PATH = \"test_model_25jobs_8vehicles.json\"  # â† Your model file\n",
        "\n",
        "# Data collection settings\n",
        "N_SAMPLES = 200\n",
        "N_COST_CANDIDATES = 5  # Number of random cost sets to try per sample\n",
        "OUTPUT_FILE = \"training_data_v2.json\"\n",
        "CHECKPOINT_EVERY = 5  # Save every 5 samples (since each takes longer)\n",
        "WAIT_SECONDS = 90  # Wait time for each optimization\n",
        "\n",
        "# Cost parameter ranges\n",
        "COST_RANGES = {\n",
        "    'costPerTravelHour': (0.5, 5.0),\n",
        "    'costPerKm': (0.014, 0.49),\n",
        "    'parking_multiplier': (0.2, 5.0)\n",
        "}\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Base URL: {BASE_URL}\")\n",
        "print(f\"  Model: {MODEL_PATH}\")\n",
        "print(f\"  Samples to collect: {N_SAMPLES}\")\n",
        "print(f\"  Cost candidates per sample: {N_COST_CANDIDATES}\")\n",
        "print(f\"  Output: {OUTPUT_FILE}\")\n",
        "print(f\"  Estimated time: {(N_SAMPLES * N_COST_CANDIDATES * WAIT_SECONDS) / 3600:.1f} hours\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collector Class with Pareto Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ParetoDataCollector:\n",
        "    \"\"\"Collects training data using Pareto-based evaluation\"\"\"\n",
        "    \n",
        "    def __init__(self, base_url, username, password, model_path, cost_ranges):\n",
        "        \"\"\"Initialize data collector\"\"\"\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.cost_ranges = cost_ranges\n",
        "        \n",
        "        # Initialize session\n",
        "        self.session = requests.Session()\n",
        "        self.session.auth = (username, password)\n",
        "        self.session.headers.update({\n",
        "            'Content-Type': 'application/json',\n",
        "            'Accept': 'application/json'\n",
        "        })\n",
        "        \n",
        "        # Load base model\n",
        "        with open(model_path, 'r') as f:\n",
        "            self.base_model = json.load(f)\n",
        "        \n",
        "        print(f\"âœ“ Base model loaded\")\n",
        "        print(f\"  Jobs: {len(self.base_model['data']['jobs'])}\")\n",
        "        print(f\"  Vehicles: {len(self.base_model['data']['vehicles'])}\")\n",
        "        \n",
        "        # Data storage\n",
        "        self.collected_data = []\n",
        "    \n",
        "    def sample_preferences(self):\n",
        "        \"\"\"Sample random preference values\"\"\"\n",
        "        preferences = {\n",
        "            'parking_importance': np.random.uniform(0.0, 1.0),\n",
        "            'time_importance': np.random.uniform(0.0, 1.0),\n",
        "            'distance_importance': np.random.uniform(0.0, 1.0)\n",
        "        }\n",
        "        return preferences\n",
        "    \n",
        "    def sample_random_costs(self):\n",
        "        \"\"\"Sample random cost parameters from valid ranges\"\"\"\n",
        "        costs = {}\n",
        "        for param, (min_val, max_val) in self.cost_ranges.items():\n",
        "            costs[param] = np.random.uniform(min_val, max_val)\n",
        "        \n",
        "        # Round for cleaner values\n",
        "        costs['costPerTravelHour'] = round(costs['costPerTravelHour'], 2)\n",
        "        costs['costPerKm'] = round(costs['costPerKm'], 4)\n",
        "        costs['parking_multiplier'] = round(costs['parking_multiplier'], 2)\n",
        "        \n",
        "        return costs\n",
        "    \n",
        "    def apply_costs_to_model(self, costs):\n",
        "        \"\"\"Apply cost parameters to model\"\"\"\n",
        "        model = copy.deepcopy(self.base_model)\n",
        "        \n",
        "        # Apply vehicle costs\n",
        "        for vehicle in model['data']['vehicles']:\n",
        "            if 'definition' in vehicle:\n",
        "                vehicle['definition']['costPerTravelHour'] = costs['costPerTravelHour']\n",
        "                vehicle['definition']['costPerKm'] = costs['costPerKm']\n",
        "        \n",
        "        # Apply parking multiplier\n",
        "        for job in model['data']['jobs']:\n",
        "            for stop in job.get('stops', []):\n",
        "                if 'parking' in stop and 'cost' in stop['parking']:\n",
        "                    original_cost = stop['parking']['cost']\n",
        "                    stop['parking']['cost'] = original_cost * costs['parking_multiplier']\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def send_to_odl(self, model, model_id):\n",
        "        \"\"\"Send model to ODL API\"\"\"\n",
        "        url = f\"{self.base_url}/models/{model_id}\"\n",
        "        \n",
        "        try:\n",
        "            response = self.session.put(url, json=model, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Upload failed: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_plan(self, model_id):\n",
        "        \"\"\"Retrieve plan from ODL API\"\"\"\n",
        "        url = f\"{self.base_url}/models/{model_id}/plan\"\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Get plan failed: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_features(self, plan):\n",
        "        \"\"\"Extract route features from plan\"\"\"\n",
        "        if not plan or 'vehiclePlans' not in plan:\n",
        "            return None\n",
        "        \n",
        "        features = {\n",
        "            'total_distance_km': 0.0,\n",
        "            'total_travel_hours': 0.0,\n",
        "            'total_cost': 0.0,\n",
        "            'num_stops': 0,\n",
        "            'num_vehicles_used': 0,\n",
        "            'unplanned_jobs': len(plan.get('unplannedJobs', [])),\n",
        "            'avg_parking_difficulty': 0.0\n",
        "        }\n",
        "        \n",
        "        total_parking_cost = 0.0\n",
        "        parking_stops = 0\n",
        "        \n",
        "        for vehicle_plan in plan['vehiclePlans']:\n",
        "            stops = vehicle_plan.get('plannedStops', [])\n",
        "            if len(stops) > 0:\n",
        "                features['num_vehicles_used'] += 1\n",
        "            \n",
        "            for stop in stops:\n",
        "                features['num_stops'] += 1\n",
        "                \n",
        "                # Accumulate metrics\n",
        "                features['total_distance_km'] += stop.get('travelDistanceFromPrevious', 0.0)\n",
        "                features['total_travel_hours'] += stop.get('travelDurationFromPrevious', 0.0) / 3600.0\n",
        "                \n",
        "                # Parking cost\n",
        "                parking = stop.get('parking', {})\n",
        "                if 'cost' in parking:\n",
        "                    total_parking_cost += parking['cost']\n",
        "                    parking_stops += 1\n",
        "        \n",
        "        # Calculate averages\n",
        "        if parking_stops > 0:\n",
        "            features['avg_parking_difficulty'] = total_parking_cost / parking_stops\n",
        "        \n",
        "        # Get total cost from statistics\n",
        "        if 'statistics' in plan and 'totalCost' in plan['statistics']:\n",
        "            features['total_cost'] = plan['statistics']['totalCost']\n",
        "        \n",
        "        # Round for cleaner values\n",
        "        features['total_distance_km'] = round(features['total_distance_km'], 2)\n",
        "        features['total_travel_hours'] = round(features['total_travel_hours'], 2)\n",
        "        features['total_cost'] = round(features['total_cost'], 2)\n",
        "        features['avg_parking_difficulty'] = round(features['avg_parking_difficulty'], 2)\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    def score_solution(self, preferences, features):\n",
        "        \"\"\"\n",
        "        Score how well a solution matches preferences.\n",
        "        Lower score = better match\n",
        "        \n",
        "        This is the key Pareto evaluation function!\n",
        "        \"\"\"\n",
        "        if features is None:\n",
        "            return float('inf')  # Invalid solution gets worst score\n",
        "        \n",
        "        score = 0.0\n",
        "        \n",
        "        # Parking importance: weight the parking difficulty\n",
        "        score += preferences['parking_importance'] * features['avg_parking_difficulty']\n",
        "        \n",
        "        # Time importance: weight the travel hours\n",
        "        score += preferences['time_importance'] * features['total_travel_hours'] * 10  # Scale up for balance\n",
        "        \n",
        "        # Distance importance: weight the distance\n",
        "        score += preferences['distance_importance'] * features['total_distance_km'] * 0.1  # Scale down for balance\n",
        "        \n",
        "        # Penalty for unplanned jobs (these are always bad)\n",
        "        score += features['unplanned_jobs'] * 1000\n",
        "        \n",
        "        return score\n",
        "    \n",
        "    def collect_sample_with_evaluation(self, sample_num, n_candidates, wait_seconds):\n",
        "        \"\"\"\n",
        "        Collect one training sample with Pareto evaluation:\n",
        "        1. Sample preferences\n",
        "        2. Try N random cost sets\n",
        "        3. Pick the one that best matches preferences\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Sample {sample_num}: Starting Pareto evaluation\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # 1. Sample preferences\n",
        "        preferences = self.sample_preferences()\n",
        "        print(f\"\\nPreferences:\")\n",
        "        print(f\"  Parking importance: {preferences['parking_importance']:.2f}\")\n",
        "        print(f\"  Time importance: {preferences['time_importance']:.2f}\")\n",
        "        print(f\"  Distance importance: {preferences['distance_importance']:.2f}\")\n",
        "        \n",
        "        # 2. Try multiple cost candidates\n",
        "        candidates = []\n",
        "        \n",
        "        for i in range(n_candidates):\n",
        "            print(f\"\\n  Candidate {i+1}/{n_candidates}:\")\n",
        "            \n",
        "            # Generate random costs\n",
        "            costs = self.sample_random_costs()\n",
        "            print(f\"    Costs: hourly={costs['costPerTravelHour']:.2f}, \"\n",
        "                  f\"km={costs['costPerKm']:.4f}, parking_mult={costs['parking_multiplier']:.2f}\")\n",
        "            \n",
        "            # Apply to model and send to API\n",
        "            model = self.apply_costs_to_model(costs)\n",
        "            model_id = f\"training_sample_{sample_num}_candidate_{i}\"\n",
        "            \n",
        "            if not self.send_to_odl(model, model_id):\n",
        "                print(f\"    âœ— Failed to send model\")\n",
        "                continue\n",
        "            \n",
        "            print(f\"    âœ“ Model uploaded, waiting {wait_seconds}s for optimization...\")\n",
        "            time.sleep(wait_seconds)\n",
        "            \n",
        "            # Get results\n",
        "            plan = self.get_plan(model_id)\n",
        "            features = self.extract_features(plan)\n",
        "            \n",
        "            if features is None:\n",
        "                print(f\"    âœ— Failed to extract features\")\n",
        "                continue\n",
        "            \n",
        "            # Score this solution\n",
        "            score = self.score_solution(preferences, features)\n",
        "            \n",
        "            print(f\"    Features: dist={features['total_distance_km']:.1f}km, \"\n",
        "                  f\"time={features['total_travel_hours']:.1f}h, \"\n",
        "                  f\"parking={features['avg_parking_difficulty']:.1f}\")\n",
        "            print(f\"    Score: {score:.2f} (lower is better)\")\n",
        "            \n",
        "            candidates.append({\n",
        "                'costs': costs,\n",
        "                'features': features,\n",
        "                'score': score\n",
        "            })\n",
        "        \n",
        "        # 3. Find best candidate\n",
        "        if len(candidates) == 0:\n",
        "            print(f\"\\nâœ— No valid candidates for sample {sample_num}\")\n",
        "            return None\n",
        "        \n",
        "        best_candidate = min(candidates, key=lambda x: x['score'])\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"BEST CANDIDATE (score: {best_candidate['score']:.2f}):\")\n",
        "        print(f\"  Costs: {best_candidate['costs']}\")\n",
        "        print(f\"  Features: {best_candidate['features']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Create training sample\n",
        "        sample = {\n",
        "            'sample_num': sample_num,\n",
        "            'preferences': preferences,\n",
        "            'costs': best_candidate['costs'],\n",
        "            'features': best_candidate['features'],\n",
        "            'score': best_candidate['score'],\n",
        "            'num_candidates_tried': len(candidates),\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def save_data(self, output_file):\n",
        "        \"\"\"Save collected data to JSON file\"\"\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(self.collected_data, f, indent=2)\n",
        "        print(f\"\\nðŸ’¾ Saved {len(self.collected_data)} samples to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate configuration\n",
        "if USERNAME == \"your-username\" or PASSWORD == \"your-password\":\n",
        "    print(\"âŒ ERROR: Please set your USERNAME and PASSWORD in the configuration cell above!\")\n",
        "else:\n",
        "    # Initialize collector\n",
        "    collector = ParetoDataCollector(\n",
        "        base_url=BASE_URL,\n",
        "        username=USERNAME,\n",
        "        password=PASSWORD,\n",
        "        model_path=MODEL_PATH,\n",
        "        cost_ranges=COST_RANGES\n",
        "    )\n",
        "    print(\"\\nâœ“ Pareto collector initialized and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test with Single Sample\n",
        "\n",
        "Run this first to make sure everything works. This will:\n",
        "- Sample 1 set of preferences\n",
        "- Try 5 different cost sets\n",
        "- Pick the best one\n",
        "\n",
        "**This will take ~7-8 minutes** (5 optimizations Ã— 90 seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with one sample\n",
        "test_sample = collector.collect_sample_with_evaluation(\n",
        "    sample_num=0,\n",
        "    n_candidates=N_COST_CANDIDATES,\n",
        "    wait_seconds=WAIT_SECONDS\n",
        ")\n",
        "\n",
        "if test_sample:\n",
        "    print(\"\\nâœ“ Test successful!\")\n",
        "    print(\"\\nSample data structure:\")\n",
        "    print(json.dumps(test_sample, indent=2))\n",
        "else:\n",
        "    print(\"\\nâœ— Test failed - check your configuration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collect Full Dataset\n",
        "\n",
        "âš ï¸ **This will take ~15-20 hours to complete!**\n",
        "\n",
        "The notebook will:\n",
        "- Collect 200 samples\n",
        "- Each sample tries 5 cost candidates (Pareto evaluation)\n",
        "- Save checkpoints every 5 samples\n",
        "- Show detailed progress\n",
        "\n",
        "You can interrupt with Kernel â†’ Interrupt and your data will be saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DATA COLLECTION PIPELINE V2 (PARETO)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Target samples: {N_SAMPLES}\")\n",
        "print(f\"Cost candidates per sample: {N_COST_CANDIDATES}\")\n",
        "print(f\"Total optimizations: {N_SAMPLES * N_COST_CANDIDATES}\")\n",
        "print(f\"Output file: {OUTPUT_FILE}\")\n",
        "print(f\"Checkpoint every: {CHECKPOINT_EVERY} samples\")\n",
        "print(f\"Wait time: {WAIT_SECONDS} seconds per optimization\")\n",
        "print(f\"Estimated total time: {(N_SAMPLES * N_COST_CANDIDATES * WAIT_SECONDS) / 3600:.1f} hours\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    for i in range(1, N_SAMPLES + 1):\n",
        "        try:\n",
        "            sample = collector.collect_sample_with_evaluation(\n",
        "                sample_num=i,\n",
        "                n_candidates=N_COST_CANDIDATES,\n",
        "                wait_seconds=WAIT_SECONDS\n",
        "            )\n",
        "            \n",
        "            if sample is not None:\n",
        "                collector.collected_data.append(sample)\n",
        "                print(f\"\\nâœ“ Sample {i} collected successfully\")\n",
        "            else:\n",
        "                print(f\"\\nâœ— Sample {i} failed, skipping...\")\n",
        "            \n",
        "            # Save checkpoint\n",
        "            if i % CHECKPOINT_EVERY == 0:\n",
        "                collector.save_data(OUTPUT_FILE)\n",
        "                elapsed = time.time() - start_time\n",
        "                avg_time = elapsed / i\n",
        "                remaining = (N_SAMPLES - i) * avg_time\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"CHECKPOINT: {i}/{N_SAMPLES} samples collected\")\n",
        "                print(f\"Elapsed: {elapsed/3600:.1f} hours\")\n",
        "                print(f\"Estimated remaining: {remaining/3600:.1f} hours\")\n",
        "                print(f\"Average time per sample: {avg_time/60:.1f} minutes\")\n",
        "                print(f\"{'='*60}\\n\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"\\nâœ— Unexpected error on sample {i}: {e}\")\n",
        "            continue\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(f\"\\n\\nInterrupted by user!\")\n",
        "    print(f\"Collected {len(collector.collected_data)} samples so far\")\n",
        "\n",
        "# Final save\n",
        "collector.save_data(OUTPUT_FILE)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DATA COLLECTION COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total samples collected: {len(collector.collected_data)}\")\n",
        "print(f\"Total time: {elapsed/3600:.1f} hours\")\n",
        "if len(collector.collected_data) > 0:\n",
        "    print(f\"Average time per sample: {(elapsed/len(collector.collected_data))/60:.1f} minutes\")\n",
        "    print(f\"Total optimizations run: {len(collector.collected_data) * N_COST_CANDIDATES}\")\n",
        "print(f\"Data saved to: {OUTPUT_FILE}\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Collected Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the collected data\n",
        "with open(OUTPUT_FILE, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"Dataset Summary:\")\n",
        "print(f\"  Total samples: {len(data)}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "df_records = []\n",
        "for sample in data:\n",
        "    record = {\n",
        "        'sample_num': sample['sample_num'],\n",
        "        **{f'pref_{k}': v for k, v in sample['preferences'].items()},\n",
        "        **{f'cost_{k}': v for k, v in sample['costs'].items()},\n",
        "        **{f'feat_{k}': v for k, v in sample['features'].items()},\n",
        "        'score': sample['score'],\n",
        "        'num_candidates_tried': sample['num_candidates_tried']\n",
        "    }\n",
        "    df_records.append(record)\n",
        "\n",
        "df = pd.DataFrame(df_records)\n",
        "\n",
        "print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\nPreferences statistics:\")\n",
        "print(df[['pref_parking_importance', 'pref_time_importance', 'pref_distance_importance']].describe())\n",
        "\n",
        "print(f\"\\nCosts statistics (these are the LEARNED optimal costs):\")\n",
        "print(df[['cost_costPerTravelHour', 'cost_costPerKm', 'cost_parking_multiplier']].describe())\n",
        "\n",
        "print(f\"\\nFeatures statistics:\")\n",
        "print(df[['feat_total_distance_km', 'feat_total_travel_hours', 'feat_avg_parking_difficulty']].describe())\n",
        "\n",
        "print(f\"\\nScore statistics (lower is better):\")\n",
        "print(df['score'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Data Quality\n",
        "\n",
        "Let's verify that the Pareto evaluation is working correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Look at a few samples where parking importance is high\n",
        "print(\"Samples with HIGH parking importance (>0.8):\")\n",
        "high_parking = df[df['pref_parking_importance'] > 0.8].head(3)\n",
        "print(high_parking[['pref_parking_importance', 'cost_parking_multiplier', \n",
        "                     'feat_avg_parking_difficulty', 'score']])\n",
        "\n",
        "print(\"\\nSamples with LOW parking importance (<0.2):\")\n",
        "low_parking = df[df['pref_parking_importance'] < 0.2].head(3)\n",
        "print(low_parking[['pref_parking_importance', 'cost_parking_multiplier', \n",
        "                    'feat_avg_parking_difficulty', 'score']])\n",
        "\n",
        "print(\"\\nExpected pattern: High parking importance should correlate with high parking_multiplier\")\n",
        "print(f\"Correlation: {df['pref_parking_importance'].corr(df['cost_parking_multiplier']):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have collected training data with Pareto evaluation:\n",
        "\n",
        "1. âœ… **Data collected**: `training_data_v2.json`\n",
        "2. âœ… **Learned from actual optimization results** (not a fixed heuristic!)\n",
        "3. ðŸ”œ **Train regression model**: preferences â†’ costs\n",
        "4. ðŸ”œ **Validate model performance**\n",
        "5. ðŸ”œ **Compare V1 vs V2 model accuracy**\n",
        "\n",
        "The V2 model should generalize better because it learned the true relationship!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
