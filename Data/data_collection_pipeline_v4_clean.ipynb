{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection Pipeline V4 - Pareto Top-N Approach\n",
        "\n",
        "## Two-Phase Approach:\n",
        "\n",
        "### Phase 1: Build Cost Pool\n",
        "- Generate random cost parameters\n",
        "- Optimize each with ODL API\n",
        "- Store (costs, features) pairs\n",
        "- Can skip if you already have cost_pool.json\n",
        "\n",
        "### Phase 2: Match Preferences (New!)\n",
        "- Generate random preferences\n",
        "- Get **top 30 solutions** from pool (closest to ideal)\n",
        "- Use **Pareto evaluation** to select best\n",
        "- Save training samples\n",
        "\n",
        "## Benefits:\n",
        "- ✅ 30 unique outputs (vs 5-7 with old method)\n",
        "- ✅ High quality (top 15% of solutions)\n",
        "- ✅ No arbitrary scaling factors\n",
        "- ✅ Ready for regression training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports successful\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import copy\n",
        "from typing import List, Dict\n",
        "\n",
        "print(\"✓ Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "**⚠️ UPDATE THESE VALUES:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded:\n",
            "  Pool size: 200\n",
            "  Training samples: 400\n",
            "  Top-N selection: 30\n",
            "  Estimated Phase 1 time: 1.7 hours\n"
          ]
        }
      ],
      "source": [
        "# API Configuration\n",
        "\n",
        "\n",
        "# Model file (use relaxed version without skill requirements)\n",
        "MODEL_PATH = \"../../test_model_mathias_fixed.json\"  # ← CHANGE THIS\n",
        "\n",
        "# Phase 1: Cost Pool Generation\n",
        "POOL_SIZE = 200  # Number of cost sets to generate\n",
        "WAIT_SECONDS = 30  # Wait time for optimization (can be 30-120s)\n",
        "CHECKPOINT_EVERY = 10  # Save progress every N samples\n",
        "POOL_FILE = \"cost_pool.json\"  # Output file\n",
        "\n",
        "# Phase 2: Training Data Generation  \n",
        "N_SAMPLES = 400  # Number of training samples to generate\n",
        "TOP_N = 30  # Use top N solutions from pool (30 = good diversity)\n",
        "OUTPUT_FILE = \"training_data_v4_pareto.json\"  # Output file\n",
        "\n",
        "# Cost parameter ranges\n",
        "COST_RANGES = {\n",
        "    'costPerTravelHour': (0.5, 5.0),\n",
        "    'costPerKm': (0.01, 0.5),\n",
        "    'parking_multiplier': (0.2, 2.0)\n",
        "}\n",
        "\n",
        "print(f\"Configuration loaded:\")\n",
        "print(f\"  Pool size: {POOL_SIZE}\")\n",
        "print(f\"  Training samples: {N_SAMPLES}\")\n",
        "print(f\"  Top-N selection: {TOP_N}\")\n",
        "print(f\"  Estimated Phase 1 time: {(POOL_SIZE * WAIT_SECONDS) / 3600:.1f} hours\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pareto Analyzer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ ParetoAnalyzer class defined\n"
          ]
        }
      ],
      "source": [
        "class ParetoAnalyzer:\n",
        "    \"\"\"Top-N + Pareto selection for cost pool matching\"\"\"\n",
        "    \n",
        "    def __init__(self, cost_pool: List[Dict]):\n",
        "        self.cost_pool = cost_pool\n",
        "        self.objectives = ['avg_parking_difficulty', 'total_travel_hours', 'total_distance_km']\n",
        "    \n",
        "    def get_top_n_solutions(self, n=30) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get top N solutions by distance to ideal point (0,0,0)\n",
        "        \n",
        "        These are the N \"best\" solutions overall, regardless of preferences.\n",
        "        \"\"\"\n",
        "        if len(self.cost_pool) == 0:\n",
        "            return []\n",
        "        \n",
        "        # Extract features for all solutions\n",
        "        all_features = np.array([[s['features'][obj] for obj in self.objectives] \n",
        "                                for s in self.cost_pool])\n",
        "        \n",
        "        # Normalize to [0, 1] range\n",
        "        min_vals = all_features.min(axis=0)\n",
        "        max_vals = all_features.max(axis=0)\n",
        "        normalized = (all_features - min_vals) / (max_vals - min_vals + 1e-10)\n",
        "        \n",
        "        # Calculate distance to ideal point (0,0,0)\n",
        "        distances = np.sqrt(np.sum(normalized**2, axis=1))\n",
        "        \n",
        "        # Select top N by lowest distance\n",
        "        n = min(n, len(self.cost_pool))  # Don't exceed pool size\n",
        "        best_indices = np.argsort(distances)[:n]\n",
        "        \n",
        "        return [self.cost_pool[i] for i in best_indices]\n",
        "    \n",
        "    def normalize_objectives(self, solutions: List[Dict]) -> np.ndarray:\n",
        "        \"\"\"Normalize objectives to [0, 1] for fair comparison\"\"\"\n",
        "        if len(solutions) == 0:\n",
        "            return np.array([])\n",
        "        \n",
        "        values = np.array([[s['features'][obj] for obj in self.objectives] \n",
        "                          for s in solutions])\n",
        "        \n",
        "        normalized = np.zeros_like(values, dtype=float)\n",
        "        for j in range(len(self.objectives)):\n",
        "            min_val = values[:, j].min()\n",
        "            max_val = values[:, j].max()\n",
        "            if max_val > min_val:\n",
        "                normalized[:, j] = (values[:, j] - min_val) / (max_val - min_val)\n",
        "            else:\n",
        "                normalized[:, j] = 0.0\n",
        "        \n",
        "        return normalized\n",
        "    \n",
        "    def select_best(self, solutions: List[Dict], preferences: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Select best solution from list using weighted Euclidean distance\n",
        "        \n",
        "        Args:\n",
        "            solutions: List of candidate solutions\n",
        "            preferences: User preference weights\n",
        "        \n",
        "        Returns:\n",
        "            Best matching solution (copy with added metadata)\n",
        "        \"\"\"\n",
        "        if len(solutions) == 0:\n",
        "            return None\n",
        "        \n",
        "        if len(solutions) == 1:\n",
        "            result = solutions[0].copy()\n",
        "            result['pareto_distance'] = 0.0\n",
        "            result['selection_pool_size'] = 1\n",
        "            return result\n",
        "        \n",
        "        # Normalize objectives\n",
        "        normalized = self.normalize_objectives(solutions)\n",
        "        \n",
        "        # Create weight vector from preferences\n",
        "        weights = np.array([\n",
        "            preferences['parking_importance'],\n",
        "            preferences['time_importance'],\n",
        "            preferences['distance_importance']\n",
        "        ])\n",
        "        \n",
        "        # Calculate weighted Euclidean distance to ideal (0,0,0)\n",
        "        distances = np.sqrt(np.sum((normalized * weights) ** 2, axis=1))\n",
        "        \n",
        "        # Select solution with minimum distance\n",
        "        best_idx = np.argmin(distances)\n",
        "        \n",
        "        # Return copy with metadata\n",
        "        result = solutions[best_idx].copy()\n",
        "        result['pareto_distance'] = float(distances[best_idx])\n",
        "        result['selection_pool_size'] = len(solutions)\n",
        "        \n",
        "        return result\n",
        "\n",
        "print(\"✓ ParetoAnalyzer class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Collector Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ CostPoolDataCollector class defined\n"
          ]
        }
      ],
      "source": [
        "class CostPoolDataCollector:\n",
        "    \"\"\"Two-phase data collector with Pareto Top-N selection\"\"\"\n",
        "    \n",
        "    def __init__(self, base_url, username, password, model_path, cost_ranges):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.cost_ranges = cost_ranges\n",
        "        \n",
        "        # Initialize session\n",
        "        self.session = requests.Session()\n",
        "        self.session.auth = (username, password)\n",
        "        self.session.headers.update({\n",
        "            'Content-Type': 'application/json',\n",
        "            'Accept': 'application/json'\n",
        "        })\n",
        "        \n",
        "        # Load base model\n",
        "        with open(model_path, 'r') as f:\n",
        "            self.base_model = json.load(f)\n",
        "        \n",
        "        print(f\"✓ Initialized\")\n",
        "        print(f\"  Jobs: {len(self.base_model['data']['jobs'])}\")\n",
        "        print(f\"  Vehicles: {len(self.base_model['data']['vehicles'])}\")\n",
        "        \n",
        "        # Data storage\n",
        "        self.cost_pool = []\n",
        "        self.training_data = []\n",
        "    \n",
        "    # ========================================================================\n",
        "    # HELPER METHODS\n",
        "    # ========================================================================\n",
        "    \n",
        "    def sample_random_costs(self):\n",
        "        \"\"\"Sample random cost parameters\"\"\"\n",
        "        costs = {}\n",
        "        for param, (min_val, max_val) in self.cost_ranges.items():\n",
        "            costs[param] = np.random.uniform(min_val, max_val)\n",
        "        \n",
        "        # Round for cleaner values\n",
        "        costs['costPerTravelHour'] = round(costs['costPerTravelHour'], 2)\n",
        "        costs['costPerKm'] = round(costs['costPerKm'], 4)\n",
        "        costs['parking_multiplier'] = round(costs['parking_multiplier'], 2)\n",
        "        \n",
        "        return costs\n",
        "    \n",
        "    def sample_preferences(self):\n",
        "        \"\"\"Sample random preferences using Dirichlet distribution\"\"\"\n",
        "        # Dirichlet ensures diversity and sum close to ~3\n",
        "        weights = np.random.dirichlet([1, 1, 1])\n",
        "        return {\n",
        "            'parking_importance': float(weights[0]),\n",
        "            'time_importance': float(weights[1]),\n",
        "            'distance_importance': float(weights[2])\n",
        "        }\n",
        "    \n",
        "    def apply_costs_to_model(self, costs):\n",
        "        \"\"\"Apply cost parameters to model\"\"\"\n",
        "        model = copy.deepcopy(self.base_model)\n",
        "        \n",
        "        # Apply vehicle costs\n",
        "        for vehicle in model['data']['vehicles']:\n",
        "            if 'definition' in vehicle:\n",
        "                vehicle['definition']['costPerTravelHour'] = costs['costPerTravelHour']\n",
        "                vehicle['definition']['costPerKm'] = costs['costPerKm']\n",
        "        \n",
        "        # Apply parking multiplier to delivery stops\n",
        "        for job in model['data']['jobs']:\n",
        "            for stop in job.get('stops', []):\n",
        "                if (stop.get('type') == 'SHIPMENT_DELIVERY' and \n",
        "                    'parking' in stop and \n",
        "                    'cost' in stop['parking'] and \n",
        "                    stop['parking']['cost'] > 0):\n",
        "                    original_cost = stop['parking']['cost']\n",
        "                    stop['parking']['cost'] = original_cost * costs['parking_multiplier']\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def send_to_odl(self, model, model_id):\n",
        "        \"\"\"Send model to ODL API\"\"\"\n",
        "        url = f\"{self.base_url}/models/{model_id}\"\n",
        "        try:\n",
        "            response = self.session.put(url, json=model, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Upload failed: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_plan(self, model_id):\n",
        "        \"\"\"Retrieve plan from ODL API\"\"\"\n",
        "        url = f\"{self.base_url}/models/{model_id}/optimiserstate/plan\"\n",
        "        try:\n",
        "            response = self.session.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Get plan failed: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def extract_features(self, plan):\n",
        "        \"\"\"Extract route features from plan\"\"\"\n",
        "        if not plan or 'vehiclePlans' not in plan:\n",
        "            return None\n",
        "        \n",
        "        features = {\n",
        "            'total_distance_km': 0.0,\n",
        "            'total_travel_hours': 0.0,\n",
        "            'total_cost': 0.0,\n",
        "            'num_stops': 0,\n",
        "            'num_vehicles_used': 0,\n",
        "            'unplanned_jobs': len(plan.get('unplannedJobs', [])),\n",
        "            'avg_parking_difficulty': 0.0\n",
        "        }\n",
        "        \n",
        "        total_parking_cost = 0.0\n",
        "        total_stops = 0\n",
        "        \n",
        "        for vehicle_plan in plan['vehiclePlans']:\n",
        "            stops = vehicle_plan.get('plannedStops', [])\n",
        "            \n",
        "            if len(stops) > 0:\n",
        "                features['num_vehicles_used'] += 1\n",
        "                features['num_stops'] += len(stops)\n",
        "                total_stops += len(stops)\n",
        "            \n",
        "            time_stats = vehicle_plan.get('timeStatistics', {})\n",
        "            features['total_distance_km'] += time_stats.get('travelMetres', 0) / 1000.0\n",
        "            features['total_travel_hours'] += time_stats.get('travelSeconds', 0) / 3600.0\n",
        "            features['total_cost'] += time_stats.get('cost', 0)\n",
        "            \n",
        "            breakdown = time_stats.get('optimiserCostBreakdown', {})\n",
        "            total_parking_cost += breakdown.get('PARKING_COST', 0.0)\n",
        "        \n",
        "        if total_stops > 0:\n",
        "            features['avg_parking_difficulty'] = total_parking_cost / total_stops\n",
        "        \n",
        "        # Round\n",
        "        features['total_distance_km'] = round(features['total_distance_km'], 2)\n",
        "        features['total_travel_hours'] = round(features['total_travel_hours'], 2)\n",
        "        features['total_cost'] = round(features['total_cost'], 2)\n",
        "        features['avg_parking_difficulty'] = round(features['avg_parking_difficulty'], 2)\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    # ========================================================================\n",
        "    # PHASE 1: BUILD COST POOL\n",
        "    # ========================================================================\n",
        "    \n",
        "    def build_cost_pool(self, pool_size, wait_seconds, checkpoint_every, pool_file):\n",
        "        \"\"\"Phase 1: Generate pool of cost sets with optimized solutions\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PHASE 1: BUILDING COST POOL\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Target: {pool_size} cost sets\")\n",
        "        print(f\"Estimated time: {(pool_size * wait_seconds) / 3600:.1f} hours\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            for i in range(1, pool_size + 1):\n",
        "                print(f\"\\nCost Set {i}/{pool_size}:\")\n",
        "                \n",
        "                try:\n",
        "                    costs = self.sample_random_costs()\n",
        "                    print(f\"  Costs: {costs['costPerTravelHour']:.2f}/h, \"\n",
        "                          f\"{costs['costPerKm']:.4f}/km, parking×{costs['parking_multiplier']:.2f}\")\n",
        "                    \n",
        "                    model = self.apply_costs_to_model(costs)\n",
        "                    model_id = f\"cost_pool_{i}\"\n",
        "                    \n",
        "                    if not self.send_to_odl(model, model_id):\n",
        "                        continue\n",
        "                    \n",
        "                    print(f\"  ✓ Uploaded, waiting {wait_seconds}s...\")\n",
        "                    time.sleep(wait_seconds)\n",
        "                    \n",
        "                    plan = self.get_plan(model_id)\n",
        "                    features = self.extract_features(plan)\n",
        "                    \n",
        "                    if features is None:\n",
        "                        print(f\"  ✗ Failed to extract features\")\n",
        "                        continue\n",
        "                    \n",
        "                    print(f\"  Features: {features['total_distance_km']:.1f}km, \"\n",
        "                          f\"{features['total_travel_hours']:.1f}h, \"\n",
        "                          f\"parking={features['avg_parking_difficulty']:.1f}, \"\n",
        "                          f\"unplanned={features['unplanned_jobs']}\")\n",
        "                    \n",
        "                    self.cost_pool.append({\n",
        "                        'pool_id': i,\n",
        "                        'costs': costs,\n",
        "                        'features': features,\n",
        "                        'timestamp': datetime.now().isoformat()\n",
        "                    })\n",
        "                    \n",
        "                    print(f\"  ✓ Added (total: {len(self.cost_pool)})\")\n",
        "                    \n",
        "                    if i % checkpoint_every == 0:\n",
        "                        self.save_cost_pool(pool_file)\n",
        "                        elapsed = time.time() - start_time\n",
        "                        remaining = ((pool_size - i) * elapsed / i)\n",
        "                        print(f\"\\n  CHECKPOINT: {len(self.cost_pool)}/{pool_size} | \"\n",
        "                              f\"Elapsed: {elapsed/3600:.1f}h | Remaining: {remaining/3600:.1f}h\\n\")\n",
        "                \n",
        "                except Exception as e:\n",
        "                    print(f\"  ✗ Error: {e}\")\n",
        "        \n",
        "        except KeyboardInterrupt:\n",
        "            print(f\"\\n\\nInterrupted! Pool has {len(self.cost_pool)} entries\")\n",
        "        \n",
        "        self.save_cost_pool(pool_file)\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PHASE 1 COMPLETE\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Cost pool: {len(self.cost_pool)} solutions\")\n",
        "        print(f\"Time: {elapsed/3600:.1f} hours\")\n",
        "        print(f\"Saved to: {pool_file}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    def save_cost_pool(self, pool_file):\n",
        "        \"\"\"Save cost pool to file\"\"\"\n",
        "        with open(pool_file, 'w') as f:\n",
        "            json.dump(self.cost_pool, f, indent=2)\n",
        "        print(f\"  💾 Saved to {pool_file}\")\n",
        "    \n",
        "    def load_cost_pool(self, pool_file):\n",
        "        \"\"\"Load cost pool from file\"\"\"\n",
        "        try:\n",
        "            with open(pool_file, 'r') as f:\n",
        "                self.cost_pool = json.load(f)\n",
        "            print(f\"✓ Loaded {len(self.cost_pool)} solutions from {pool_file}\")\n",
        "            return True\n",
        "        except FileNotFoundError:\n",
        "            print(f\"✗ File not found: {pool_file}\")\n",
        "            return False\n",
        "    \n",
        "    # ========================================================================\n",
        "    # PHASE 2: MATCH PREFERENCES TO POOL (PARETO TOP-N)\n",
        "    # ========================================================================\n",
        "    \n",
        "    def find_best_match(self, preferences, top_n=30):\n",
        "        \"\"\"\n",
        "        Find best match using Pareto Top-N selection\n",
        "        \n",
        "        Process:\n",
        "        1. Get top N solutions (closest to ideal point)\n",
        "        2. Select best using weighted Pareto evaluation\n",
        "        \"\"\"\n",
        "        if len(self.cost_pool) == 0:\n",
        "            return None\n",
        "        \n",
        "        analyzer = ParetoAnalyzer(self.cost_pool)\n",
        "        top_solutions = analyzer.get_top_n_solutions(n=top_n)\n",
        "        best_match = analyzer.select_best(top_solutions, preferences)\n",
        "        \n",
        "        return best_match\n",
        "    \n",
        "    def generate_training_samples(self, n_samples, top_n, output_file):\n",
        "        \"\"\"Phase 2: Generate training samples using Pareto Top-N\"\"\"\n",
        "        if len(self.cost_pool) == 0:\n",
        "            print(\"✗ Cost pool is empty! Load or build first.\")\n",
        "            return\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PHASE 2: GENERATING TRAINING SAMPLES\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Cost pool: {len(self.cost_pool)} solutions\")\n",
        "        print(f\"Target samples: {n_samples}\")\n",
        "        print(f\"Top-N selection: {top_n}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        \n",
        "        self.training_data = []\n",
        "        \n",
        "        for i in range(1, n_samples + 1):\n",
        "            print(f\"\\rSample {i}/{n_samples}\", end='', flush=True)\n",
        "            \n",
        "            preferences = self.sample_preferences()\n",
        "            match = self.find_best_match(preferences, top_n=top_n)\n",
        "            \n",
        "            if match is None:\n",
        "                continue\n",
        "            \n",
        "            sample = {\n",
        "                'sample_id': i,\n",
        "                'preferences': preferences,\n",
        "                'costs': match['costs'],\n",
        "                'features': match['features'],\n",
        "                'metadata': {\n",
        "                    'pool_id': match['pool_id'],\n",
        "                    'pareto_distance': match['pareto_distance'],\n",
        "                    'selection_pool_size': match['selection_pool_size'],\n",
        "                    'timestamp': datetime.now().isoformat()\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            self.training_data.append(sample)\n",
        "        \n",
        "        # Save\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(self.training_data, f, indent=2)\n",
        "        \n",
        "        print(f\"\\n\\n{'='*60}\")\n",
        "        print(f\"PHASE 2 COMPLETE\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Generated: {len(self.training_data)} samples\")\n",
        "        print(f\"Saved to: {output_file}\")\n",
        "        \n",
        "        # Statistics\n",
        "        pool_ids = [s['metadata']['pool_id'] for s in self.training_data]\n",
        "        unique_ids = len(set(pool_ids))\n",
        "        print(f\"\\nDiversity: {unique_ids} unique solutions used\")\n",
        "        print(f\"Avg samples per solution: {len(self.training_data) / unique_ids:.1f}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(\"✓ CostPoolDataCollector class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Initialized\n",
            "  Jobs: 106\n",
            "  Vehicles: 26\n"
          ]
        }
      ],
      "source": [
        "collector = CostPoolDataCollector(\n",
        "    base_url=BASE_URL,\n",
        "    username=USERNAME,\n",
        "    password=PASSWORD,\n",
        "    model_path=MODEL_PATH,\n",
        "    cost_ranges=COST_RANGES\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Phase 1: Build Cost Pool (or Load Existing)\n",
        "\n",
        "**If you already have cost_pool.json, skip to Phase 2!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Loaded 200 solutions from cost_pool.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Option A: Load existing pool\n",
        "collector.load_cost_pool(POOL_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B: Build new pool (takes ~6 hours for 200 samples at 30s each)\n",
        "collector.build_cost_pool(\n",
        "    pool_size=POOL_SIZE,\n",
        "    wait_seconds=WAIT_SECONDS,\n",
        "    checkpoint_every=CHECKPOINT_EVERY,\n",
        "    pool_file=POOL_FILE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Analyze Cost Pool (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost pool analysis:\n",
            "  Total solutions: 200\n",
            "  Top 30 solutions: 30\n",
            "  Top 30 = top 15.0%\n",
            "\n",
            "  Unplanned jobs: min=20, max=20, avg=20.0\n",
            "  ⚠️  Consider using relaxed model (remove skill requirements)\n"
          ]
        }
      ],
      "source": [
        "# Quick analysis\n",
        "if len(collector.cost_pool) > 0:\n",
        "    analyzer = ParetoAnalyzer(collector.cost_pool)\n",
        "    top_30 = analyzer.get_top_n_solutions(n=30)\n",
        "    \n",
        "    print(f\"Cost pool analysis:\")\n",
        "    print(f\"  Total solutions: {len(collector.cost_pool)}\")\n",
        "    print(f\"  Top 30 solutions: {len(top_30)}\")\n",
        "    print(f\"  Top 30 = top {100*len(top_30)/len(collector.cost_pool):.1f}%\")\n",
        "    \n",
        "    # Check unplanned jobs\n",
        "    unplanned = [s['features']['unplanned_jobs'] for s in collector.cost_pool]\n",
        "    print(f\"\\n  Unplanned jobs: min={min(unplanned)}, max={max(unplanned)}, avg={np.mean(unplanned):.1f}\")\n",
        "    if max(unplanned) > 5:\n",
        "        print(f\"  ⚠️  Consider using relaxed model (remove skill requirements)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Phase 2: Generate Training Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "PHASE 2: GENERATING TRAINING SAMPLES\n",
            "============================================================\n",
            "Cost pool: 200 solutions\n",
            "Target samples: 400\n",
            "Top-N selection: 30\n",
            "============================================================\n",
            "\n",
            "Sample 400/400\n",
            "\n",
            "============================================================\n",
            "PHASE 2 COMPLETE\n",
            "============================================================\n",
            "Generated: 400 samples\n",
            "Saved to: training_data_v4_pareto.json\n",
            "\n",
            "Diversity: 5 unique solutions used\n",
            "Avg samples per solution: 80.0\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate training data using Pareto Top-N\n",
        "collector.generate_training_samples(\n",
        "    n_samples=N_SAMPLES,\n",
        "    top_n=TOP_N,\n",
        "    output_file=OUTPUT_FILE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. View Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"sample_id\": 1,\n",
            "  \"preferences\": {\n",
            "    \"parking_importance\": 0.2211968236503381,\n",
            "    \"time_importance\": 0.19164522938840747,\n",
            "    \"distance_importance\": 0.5871579469612545\n",
            "  },\n",
            "  \"costs\": {\n",
            "    \"costPerTravelHour\": 1.23,\n",
            "    \"costPerKm\": 0.3214,\n",
            "    \"parking_multiplier\": 0.42\n",
            "  },\n",
            "  \"features\": {\n",
            "    \"total_distance_km\": 1001.33,\n",
            "    \"total_travel_hours\": 30.4,\n",
            "    \"total_cost\": 450131.92,\n",
            "    \"num_stops\": 172,\n",
            "    \"num_vehicles_used\": 8,\n",
            "    \"unplanned_jobs\": 20,\n",
            "    \"avg_parking_difficulty\": 87.99\n",
            "  },\n",
            "  \"metadata\": {\n",
            "    \"pool_id\": 4,\n",
            "    \"pareto_distance\": 0.15907641614065898,\n",
            "    \"selection_pool_size\": 30,\n",
            "    \"timestamp\": \"2025-10-29T10:04:45.595817\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Show first training sample\n",
        "if len(collector.training_data) > 0:\n",
        "    print(json.dumps(collector.training_data[0], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done! 🎉\n",
        "\n",
        "You now have training data with:\n",
        "- ~30 unique cost combinations (from top 15% of pool)\n",
        "- 400 samples total\n",
        "- ~13 samples per unique output\n",
        "- Ready for regression training!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
