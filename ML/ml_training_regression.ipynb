{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Model Training: Preferences → Cost Parameters\n",
        "\n",
        "Train a regression model to translate user preferences into ODL cost parameters.\n",
        "\n",
        "## Goal:\n",
        "- **Input:** User preferences (parking, time, distance importance)\n",
        "- **Output:** Cost parameters (costPerTravelHour, costPerKm, parking_multiplier)\n",
        "\n",
        "## Approach:\n",
        "1. Load training data from Pareto Top-N selection\n",
        "2. Train multiple regression models\n",
        "3. Evaluate and compare\n",
        "4. Save best model for deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"✓ Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data file\n",
        "TRAINING_DATA_FILE = 'training_data_v4.json'  # ← Your training data\n",
        "\n",
        "# Model save path\n",
        "MODEL_SAVE_PATH = 'preference_to_cost_model.pkl'\n",
        "SCALER_SAVE_PATH = 'preference_scaler.pkl'\n",
        "\n",
        "# Train/test split\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Training data: {TRAINING_DATA_FILE}\")\n",
        "print(f\"  Test size: {TEST_SIZE*100:.0f}%\")\n",
        "print(f\"  Model output: {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "with open(TRAINING_DATA_FILE, 'r') as f:\n",
        "    training_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(training_data)} training samples\")\n",
        "\n",
        "# Show first sample\n",
        "print(\"\\nSample structure:\")\n",
        "print(json.dumps(training_data[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame for easier analysis\n",
        "data = []\n",
        "for sample in training_data:\n",
        "    row = {\n",
        "        # Inputs\n",
        "        'parking_importance': sample['preferences']['parking_importance'],\n",
        "        'time_importance': sample['preferences']['time_importance'],\n",
        "        'distance_importance': sample['preferences']['distance_importance'],\n",
        "        # Outputs\n",
        "        'costPerTravelHour': sample['costs']['costPerTravelHour'],\n",
        "        'costPerKm': sample['costs']['costPerKm'],\n",
        "        'parking_multiplier': sample['costs']['parking_multiplier'],\n",
        "        # Metadata\n",
        "        'pool_id': sample['metadata']['pool_id'],\n",
        "        'pareto_distance': sample['metadata']['pareto_distance']\n",
        "    }\n",
        "    data.append(row)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"Dataset Statistics:\\n\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check output diversity\n",
        "unique_costs = df[['costPerTravelHour', 'costPerKm', 'parking_multiplier']].drop_duplicates()\n",
        "print(f\"\\nUnique cost combinations: {len(unique_costs)}\")\n",
        "print(f\"Samples per unique output: {len(df) / len(unique_costs):.1f}\")\n",
        "\n",
        "# Check pool_id distribution\n",
        "pool_id_counts = df['pool_id'].value_counts()\n",
        "print(f\"\\nMost common pool_id: {pool_id_counts.index[0]} ({pool_id_counts.iloc[0]} times)\")\n",
        "print(f\"Least common pool_id: {pool_id_counts.index[-1]} ({pool_id_counts.iloc[-1]} times)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize input distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].hist(df['parking_importance'], bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Parking Importance Distribution')\n",
        "axes[0].set_xlabel('Importance')\n",
        "\n",
        "axes[1].hist(df['time_importance'], bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[1].set_title('Time Importance Distribution')\n",
        "axes[1].set_xlabel('Importance')\n",
        "\n",
        "axes[2].hist(df['distance_importance'], bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[2].set_title('Distance Importance Distribution')\n",
        "axes[2].set_xlabel('Importance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Inputs are well-distributed (Dirichlet sampling)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize output distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].hist(df['costPerTravelHour'], bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[0].set_title(f'Cost Per Travel Hour\\n({len(df[\"costPerTravelHour\"].unique())} unique values)')\n",
        "axes[0].set_xlabel('Cost ($/hour)')\n",
        "\n",
        "axes[1].hist(df['costPerKm'], bins=20, edgecolor='black', alpha=0.7, color='green')\n",
        "axes[1].set_title(f'Cost Per Km\\n({len(df[\"costPerKm\"].unique())} unique values)')\n",
        "axes[1].set_xlabel('Cost ($/km)')\n",
        "\n",
        "axes[2].hist(df['parking_multiplier'], bins=20, edgecolor='black', alpha=0.7, color='red')\n",
        "axes[2].set_title(f'Parking Multiplier\\n({len(df[\"parking_multiplier\"].unique())} unique values)')\n",
        "axes[2].set_xlabel('Multiplier')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features (X) and targets (y)\n",
        "X = df[['parking_importance', 'time_importance', 'distance_importance']].values\n",
        "y = df[['costPerTravelHour', 'costPerKm', 'parking_multiplier']].values\n",
        "\n",
        "print(f\"X shape: {X.shape}  (preferences)\")\n",
        "print(f\"y shape: {y.shape}  (cost parameters)\")\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set:  {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Standardize inputs (may help neural networks)\n",
        "# For tree-based models, this is not necessary\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"✓ Data standardized for neural networks\")\n",
        "print(f\"  Mean: {X_train_scaled.mean(axis=0)}\")\n",
        "print(f\"  Std:  {X_train_scaled.std(axis=0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Multiple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models to try\n",
        "models = {}\n",
        "\n",
        "# 1. Random Forest (usually best for this type of problem)\n",
        "models['Random Forest'] = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 2. Gradient Boosting\n",
        "models['Gradient Boosting'] = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 3. Neural Network (use scaled data)\n",
        "models['Neural Network'] = MLPRegressor(\n",
        "    hidden_layer_sizes=(64, 32, 16),\n",
        "    activation='relu',\n",
        "    max_iter=1000,\n",
        "    early_stopping=True,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"Training {len(models)} models...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models and collect results\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    # Use scaled data for Neural Network, original for others\n",
        "    if name == 'Neural Network':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics for each output\n",
        "    metrics = {}\n",
        "    output_names = ['costPerTravelHour', 'costPerKm', 'parking_multiplier']\n",
        "    \n",
        "    for i, out_name in enumerate(output_names):\n",
        "        mse = mean_squared_error(y_test[:, i], y_pred[:, i])\n",
        "        mae = mean_absolute_error(y_test[:, i], y_pred[:, i])\n",
        "        r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
        "        \n",
        "        metrics[out_name] = {\n",
        "            'MSE': mse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        }\n",
        "    \n",
        "    # Overall R2\n",
        "    overall_r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'predictions': y_pred,\n",
        "        'metrics': metrics,\n",
        "        'overall_r2': overall_r2\n",
        "    }\n",
        "    \n",
        "    print(f\"  Overall R² = {overall_r2:.4f}\")\n",
        "    for out_name, m in metrics.items():\n",
        "        print(f\"    {out_name}: R²={m['R2']:.4f}, MAE={m['MAE']:.4f}\")\n",
        "\n",
        "print(\"\\n✓ All models trained!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compare Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "comparison = []\n",
        "for name, result in results.items():\n",
        "    row = {'Model': name, 'Overall R²': result['overall_r2']}\n",
        "    for out_name, metrics in result['metrics'].items():\n",
        "        row[f'{out_name} R²'] = metrics['R2']\n",
        "        row[f'{out_name} MAE'] = metrics['MAE']\n",
        "    comparison.append(row)\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison)\n",
        "comparison_df = comparison_df.sort_values('Overall R²', ascending=False)\n",
        "\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Find best model\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_r2 = comparison_df.iloc[0]['Overall R²']\n",
        "print(f\"\\n🏆 Best Model: {best_model_name} (R² = {best_r2:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualize Best Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get best model predictions\n",
        "best_model = results[best_model_name]['model']\n",
        "best_predictions = results[best_model_name]['predictions']\n",
        "\n",
        "# Plot predictions vs actual for each output\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "output_names = ['costPerTravelHour', 'costPerKm', 'parking_multiplier']\n",
        "\n",
        "for i, (ax, name) in enumerate(zip(axes, output_names)):\n",
        "    ax.scatter(y_test[:, i], best_predictions[:, i], alpha=0.6, s=50)\n",
        "    \n",
        "    # Perfect prediction line\n",
        "    min_val = min(y_test[:, i].min(), best_predictions[:, i].min())\n",
        "    max_val = max(y_test[:, i].max(), best_predictions[:, i].max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect prediction')\n",
        "    \n",
        "    r2 = results[best_model_name]['metrics'][name]['R2']\n",
        "    mae = results[best_model_name]['metrics'][name]['MAE']\n",
        "    \n",
        "    ax.set_xlabel(f'Actual {name}')\n",
        "    ax.set_ylabel(f'Predicted {name}')\n",
        "    ax.set_title(f'{name}\\nR² = {r2:.4f}, MAE = {mae:.4f}')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'{best_model_name} - Predictions vs Actual', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual plot\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, (ax, name) in enumerate(zip(axes, output_names)):\n",
        "    residuals = y_test[:, i] - best_predictions[:, i]\n",
        "    \n",
        "    ax.scatter(best_predictions[:, i], residuals, alpha=0.6, s=50)\n",
        "    ax.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel(f'Predicted {name}')\n",
        "    ax.set_ylabel('Residuals')\n",
        "    ax.set_title(f'{name} Residuals')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'{best_model_name} - Residual Analysis', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ If residuals are randomly scattered around 0, the model is unbiased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Feature Importance (for tree-based models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance for Random Forest or Gradient Boosting\n",
        "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
        "    feature_names = ['parking_importance', 'time_importance', 'distance_importance']\n",
        "    \n",
        "    # Get feature importances\n",
        "    importances = best_model.feature_importances_\n",
        "    \n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(feature_names, importances, edgecolor='black', alpha=0.7)\n",
        "    plt.title(f'Feature Importance - {best_model_name}')\n",
        "    plt.ylabel('Importance')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Feature Importances:\")\n",
        "    for name, imp in zip(feature_names, importances):\n",
        "        print(f\"  {name}: {imp:.4f}\")\n",
        "else:\n",
        "    print(f\"Feature importance not available for {best_model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Test on New Preferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test predictions on some example preferences\n",
        "test_cases = [\n",
        "    {'parking_importance': 0.8, 'time_importance': 0.1, 'distance_importance': 0.1},\n",
        "    {'parking_importance': 0.1, 'time_importance': 0.8, 'distance_importance': 0.1},\n",
        "    {'parking_importance': 0.1, 'time_importance': 0.1, 'distance_importance': 0.8},\n",
        "    {'parking_importance': 0.33, 'time_importance': 0.33, 'distance_importance': 0.34}\n",
        "]\n",
        "\n",
        "print(\"Test Predictions:\\n\")\n",
        "\n",
        "for i, prefs in enumerate(test_cases, 1):\n",
        "    X_new = np.array([[prefs['parking_importance'], \n",
        "                      prefs['time_importance'], \n",
        "                      prefs['distance_importance']]])\n",
        "    \n",
        "    # Scale if using Neural Network\n",
        "    if best_model_name == 'Neural Network':\n",
        "        X_new = scaler.transform(X_new)\n",
        "    \n",
        "    prediction = best_model.predict(X_new)[0]\n",
        "    \n",
        "    print(f\"Case {i}: parking={prefs['parking_importance']:.2f}, \"\n",
        "          f\"time={prefs['time_importance']:.2f}, \"\n",
        "          f\"distance={prefs['distance_importance']:.2f}\")\n",
        "    print(f\"  Predicted costs:\")\n",
        "    print(f\"    costPerTravelHour = {prediction[0]:.2f}\")\n",
        "    print(f\"    costPerKm = {prediction[1]:.4f}\")\n",
        "    print(f\"    parking_multiplier = {prediction[2]:.2f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Save Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\"✓ Best model ({best_model_name}) saved to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# Save scaler if using Neural Network\n",
        "if best_model_name == 'Neural Network':\n",
        "    with open(SCALER_SAVE_PATH, 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "    print(f\"✓ Scaler saved to: {SCALER_SAVE_PATH}\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'model_type': best_model_name,\n",
        "    'overall_r2': float(best_r2),\n",
        "    'training_samples': len(X_train),\n",
        "    'test_samples': len(X_test),\n",
        "    'unique_outputs': int(len(unique_costs)),\n",
        "    'metrics': {name: {k: float(v) for k, v in metrics.items()} \n",
        "                for name, metrics in results[best_model_name]['metrics'].items()},\n",
        "    'input_features': ['parking_importance', 'time_importance', 'distance_importance'],\n",
        "    'output_features': ['costPerTravelHour', 'costPerKm', 'parking_multiplier'],\n",
        "    'requires_scaling': best_model_name == 'Neural Network'\n",
        "}\n",
        "\n",
        "with open('model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"✓ Metadata saved to: model_metadata.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Model Usage Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: How to load and use the saved model\n",
        "print(\"Example usage code:\\n\")\n",
        "print(\"\"\"\n",
        "# Load model\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open('preference_to_cost_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Optional: Load scaler if using Neural Network\n",
        "# with open('preference_scaler.pkl', 'rb') as f:\n",
        "#     scaler = pickle.load(f)\n",
        "\n",
        "# Get user preferences\n",
        "preferences = {\n",
        "    'parking_importance': 0.7,\n",
        "    'time_importance': 0.2,\n",
        "    'distance_importance': 0.1\n",
        "}\n",
        "\n",
        "# Prepare input\n",
        "X = np.array([[\n",
        "    preferences['parking_importance'],\n",
        "    preferences['time_importance'],\n",
        "    preferences['distance_importance']\n",
        "]])\n",
        "\n",
        "# Scale if needed\n",
        "# X = scaler.transform(X)  # Only for Neural Network\n",
        "\n",
        "# Predict costs\n",
        "costs = model.predict(X)[0]\n",
        "\n",
        "result = {\n",
        "    'costPerTravelHour': costs[0],\n",
        "    'costPerKm': costs[1],\n",
        "    'parking_multiplier': costs[2]\n",
        "}\n",
        "\n",
        "print(result)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✅ Trained multiple regression models\n",
        "✅ Evaluated and compared performance\n",
        "✅ Saved best model for deployment\n",
        "✅ Model translates preferences → cost parameters\n",
        "\n",
        "### Next Steps:\n",
        "1. Integrate model into your application\n",
        "2. Get user preferences (parking, time, distance importance)\n",
        "3. Predict cost parameters using model\n",
        "4. Send costs to ODL API for route optimization\n",
        "5. Return optimized routes to user!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
